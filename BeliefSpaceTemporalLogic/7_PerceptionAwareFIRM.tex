\documentclass[conference]{IEEEtran}
\usepackage{standalone}
\usepackage{times}
\usepackage{float}
\usepackage{biblatex}
\addbibresource{7_refs.bib}


\input{TemplateFiles/def.tex}
\input{TemplateFiles/inc}

% numbers option provides compact numerical references in the text. 

\pdfinfo{
   /Author (Homer Simpson)
   /Title  (Robots: Our new overlords)
   /CreationDate (D:20101201120000)
   /Subject (Robots)
   /Keywords (Robots;Overlords)
}

% Table caption wrangling
\usepackage{etoolbox}
\makeatletter
\patchcmd{\@makecaption}
  {\scshape}
  {}
  {}
  {}
\makeatletter
\patchcmd{\@makecaption}
  {\\}
  {.\ }
  {}
  {}
\makeatother

\newcommand{\Ali}[1]{{\color{green} Ali: #1}}
\newcommand{\cristi}[1]{{\color{orange} Cristi: #1}}
\newcommand{\rohan}[1]{{\color{blue} Rohan: #1}}
\allowdisplaybreaks[1]

\begin{document}

% paper title
%\title{\large From Mission Specification to Safe Control Logic Under Uncertainty:\\ Application to Mars Copter-Rover Navigation-Coordination}

\title{\huge Vision Aware FIRM}

\author{Rohan, Ali, Kamak, Cristi, Petter, Sofie, Richard, Murray, Aaron Ames}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
\end{abstract}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

\section{Related work}
\cite{achtelik2014motion}

\cite{costante2018exploiting}

\cite{perception-aware-planning} 

\cite{Perception-Aware-Multiobjective-Search}

\cite{MapQualityEvaluation}

\section{Sensor Model}
Let $P \in \mathbb{R}^{3}$ represent a 3-d point, $p \in \mathbb{R}^2$ represent represent a point in the image space and $\pi_\theta:\mathbb{R}^3\to\mathbb{R}^2$ be the camera projection model assuming that the intrinsic camera parameters are known and $\theta$ represents the pose of the camera in the world frame.

The equation below projects a point $P$ in the world frame to image space of $k^{th}$ camera frame:
\begin{equation} p=\pi_\theta(^{w}P) \end{equation}
We can retrieve the 3-d point in the world frame from a point in the image space and known depth, using: 
\begin{equation} ^{w}P=\pi^{-1}_\theta(p,d) \end{equation}
The pose of the camera $\theta$ can be estimated by minimizing the re-projection error, as shown in the equation below. Where, $\theta_{kf}$ represents the pose of the keyframe and $p_z$ represents the measure location of the feature point in the image space.
\begin{equation}
     \theta = \underset{\theta}{\arg\min}~~||p_z - \pi_\theta(\pi^{-1}_{\theta_{kf}}(p,d))||^2
\end{equation}
\printbibliography

\end{document}
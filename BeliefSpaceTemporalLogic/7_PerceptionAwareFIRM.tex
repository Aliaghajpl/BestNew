\documentclass[conference]{IEEEtran}
\usepackage{standalone}
\usepackage{times}
\usepackage{float}
\usepackage{biblatex}
\addbibresource{7_refs.bib}


\input{TemplateFiles/def.tex}
\input{TemplateFiles/inc}

% numbers option provides compact numerical references in the text. 

\pdfinfo{
   /Author (Homer Simpson)
   /Title  (Robots: Our new overlords)
   /CreationDate (D:20101201120000)
   /Subject (Robots)
   /Keywords (Robots;Overlords)
}

% Table caption wrangling
\usepackage{etoolbox}
\makeatletter
\patchcmd{\@makecaption}
  {\scshape}
  {}
  {}
  {}
\makeatletter
\patchcmd{\@makecaption}
  {\\}
  {.\ }
  {}
  {}
\makeatother

\newcommand{\Ali}[1]{{\color{green} Ali: #1}}
\newcommand{\cristi}[1]{{\color{orange} Cristi: #1}}
\newcommand{\rohan}[1]{{\color{blue} Rohan: #1}}
\allowdisplaybreaks[1]

\begin{document}

% paper title
%\title{\large From Mission Specification to Safe Control Logic Under Uncertainty:\\ Application to Mars Copter-Rover Navigation-Coordination}

\title{\huge Vision Aware FIRM}

\author{Rohan, Ali, Kamak, Cristi, Petter, Sofie, Richard, Murray, Aaron Ames}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
\end{abstract}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related work}
\cite{achtelik2014motion}

\cite{costante2018exploiting}

\cite{perception-aware-planning} 

\cite{Perception-Aware-Multiobjective-Search}

\cite{MapQualityEvaluation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem Definition}
\subsection{General}
For state $x$ and control input $u$ motion and observation model are defined as follows:
\begin{align}
x_{k+1} &= f(x_k, u_k, w_k), w_k \sim p(w_k|x_k,u_k) \\
z_k &= h(x_k, v_k), v_k \sim p(v_k|x_k)
\end{align}

A belief state $b$ is a posterior distribution over all past actions and observations and it's evolution is as follows:
\begin{align}
    b_{k+1} &= p(x_{k+1}|z_{0:k+1}, u_{0:k}) \\
            &= \tau(b_k,u_k,z_{k+1})
\end{align} 

A policy $\pi : \mathbb{B} \to \mathbb{U}$ is a mapping from belief to a control input.

\pr{Problem} The overall problem is:
\begin{align}
\pi^{*} &= \arg\min \mathbb{E}\\
\nonumber & \Pr(x\in F) < \epsilon \\
\nonumber & u_{min} < u_i < u_{max}
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivation}
Talk about degenerate configurations with figures.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Sensor Model}

\pr{Map Representation}
define keyframes, feature points

\pr{Sensor Model:}
describe projection

Let $P \in \mathbb{R}^{3}$ represent a 3-d point, $p \in \mathbb{R}^2$ represent represent a point in the image space and $\pi_\theta:\mathbb{R}^3\to\mathbb{R}^2$ be the camera projection model assuming that the intrinsic camera parameters are known and $\theta$ represents the pose of the camera in the world frame.

The equation below projects a point $P$ in the world frame to image space of $k^{th}$ camera frame:
\begin{equation} p=\pi_\theta(^{w}P) \end{equation}
We can retrieve the 3-d point in the world frame from a point in the image space and known depth, using: 
\begin{equation} ^{w}P=\pi^{-1}_\theta(p,d) \end{equation}

The sensor model is obtained by using the following equation, where $\Sigma_o$ is covariance of the image noise (estimation of location of the feature points).
\begin{equation}
     z_p = h(\theta,v)=
     \pi_\theta(\pi^{-1}_{\theta_{kf}}(p,d)) + v,~~~ v\sim \mathcal{N}(0,\Sigma_{o})
     \label{eq:ObsModel}
\end{equation}

\rohan{TODO: Define feature and }
\pr{Keyframe}
\pr{Feature}
\\
The pose of the camera $\theta$ can be estimated by minimizing the re-projection error, as shown in the equation below. Where, $\theta_{kf}$ represents the pose of the keyframe and $p_z$ represents the measure location of the feature point in the image space.
\begin{equation}
     \theta = \underset{\theta}{\arg\min}~\Sigma ||z_{p_i} - \pi_\theta(\pi^{-1}_{\theta_{kf}}(p_i,d_i))||^2_{\Sigma_o}
\end{equation}

Information $\mathcal{I}$ can be found using the following equation:
\begin{equation}
     \mathcal{I} = J^{T}\Sigma^{-1}_{o}J
\end{equation}
for
\begin{equation}
     J = \frac{dh}{d\theta}
\end{equation}

Advantages:
\begin{itemize}
    \item Computationally more efficient than direct or homography based approaches.
    \item Does not require homography assumptions like planar scenes, etc.
\end{itemize}

Challenges:
\begin{itemize}
    \item Efficiently finding all the feature points in the field for a given camera pose $\theta$.
    \item Acquiring set of keyframes from an elevation map of the environment.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Planning}\label{sec:planning}

\pr{Cost Graph in Belief Space}

\pr{Dynamic-aware Local Planning in Belief Space}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment}\label{sec:experiment}

\subsection{Rover}
The dynamics of the rover are given by unicycle model:
\begin{equation}
    \begin{bmatrix}
        x(t+1) \\
        y(t+1) \\
        \psi(t+1)
    \end{bmatrix} = \begin{bmatrix}x(t) + v \cos(\psi(t)) \delta{t}\\ y(t) + v \sin(\psi(t)) \delta{t}\\ \psi(t) + \omega \delta{t} \end{bmatrix} + w,
\end{equation}
where position of the rover is given by $(x,y)$, its heading is given by $\psi$ and it is corrupted by Gaussian noise $w \sim \mathcal{N}(0,\Sigma)$. \\
\rohan{Do we incorporate roll and pitch in the dynamics?}

\subsection{Copter}
\pr{Dynamics} \\
% Better localization for map creation or avoiding obstacle
The dynamics of the quadrotor are given by the following equations:
\begin{gather}
m\ddot{x} = mge_{3} - fRe_{3} + w^f\\
\dot{R} = R\hat{\Omega} \\
J\dot{\Omega} + \Omega \times J\Omega = M + w^m
\end{gather}
where the state of the copter is given by position, velocity, acceleration $x, \dot{x}, \ddot{x} \in \mathbb{R}^3$, orientation $R \in SO(3)$ and angular velocity $\Omega \in \mathbb{R}^3$.
Control input is the total thrust $f \in \mathbb{R}$ and moment $M \in \mathbb{R}^3$.
Parameters of the system are mass $m$, intertia matrix $J$ and gravity $g$.
Hat map $\hat{.}: \mathbb{R}^3 \to \mathfrak{so}(3)$ is defined by the condition $a \times b = \hat{a}b$ where $a,b\in \mathbb{R}^3$, and $\times$ is the vector cross-product operator. The position and attitude dynamics are corrupted by gaussian disturbances  $w^f, w^m \sim \mathcal{N}(0,\Sigma)$. \\

\pr{Local Controller}
The following controller \cite{leegeometric} provides almost global exponential attractiveness for position and attitude dynamics:
\begin{gather}
    e_x = x - x_d \\
    e_v = v - v_d \\
    e_R = \frac{1}{2}(R^T_d R - R^T R_d)^{\vee} \\
    e_{\Omega} = \Omega - R^T R_d \Omega_d \\
    f = -(-k_x e_x - k_v e_v - mge_3 + m\ddot{x}_d).Re_3 \\
    \nonumber M = -k_R e_R - k_{\Omega} e_{\Omega} + \Omega \times J\Omega\\ - J (\hat{\Omega} R^T R_d \Omega_d - R^T R_d \dot{\Omega}_d)
\end{gather}

\pr{Differential Flatness} The quadcopter dynamics are differentially flat. Thus, control input $u$ and state $x$ can be written as algebraic function $\alpha$ of flat variables $x^f = [x, y, z, \psi] \in \mathbb{R}^3 \times SO(2)$ and their derivatives.

\begin{align}
(u_t, x_t) = \alpha(x_t^f,\dot{x}_t^f,\ddot{x}_t^f,\dddot{x}_t^f,\ddddot{x}_t^f)
\end{align}

\pr{State}
\begin{align}
X_t = (x_t^f,\dot{x}_t^f,\ddot{x}_t^f,\dddot{x}_t^f,\ddddot{x}_t^f)
\end{align}


\begin{align}
(u^{ij}_{0:T}, x^{ij}_{0:T}) = mp(X^i,X^j,T)
\end{align}

\begin{align}
(u^{ij}_{0:T}, x^{ij}_{0:T},T) = tomp(X^i,X^j)
\end{align}

\begin{align}
(u, x) = \alpha(X)
\end{align}


\begin{align}
(u^{ij}_{0:T}, x^{ij}_{0:T},T) = tomp(x^{f,i},x^{f,j})
\end{align}

\pr{Policy}
Since the quadrotor system is deferentially flat, given a sufficiently smooth trajectory in flat space $x^f(t): t \to \mathbb{R}^3\times SO(2)$ we can obtain the trajectory of state $x(t)$ and control inputs $u(t)$. 
Also, $x(t) \in \mathbb{C}^4$ to ensure that the trajectories are kinodynamically feasible. 
We represent the trajectories as a sequence of $9^{th}$ order polynomials:
\begin{align}
x^f_t = 
\begin{cases}
    \sum_{i=0}^9 c_i^1 t^i, & 0 < t < T_1 \\
    \sum_{i=0}^9 c_i^2 t^i, & T_1 < t < T_2 \\
    \vdots\\
    \sum_{i=0}^9 c_i^N t^i, & T_{N-1} < t < T_N
\end{cases}
\end{align}
where $c^k_i\in\mathbb{R}^4$. 

Further continuity constraints on the above polynomials can be enforced by:
\begin{align}
A(\bar{T}) \bar{c} = b    
\end{align}
where $\bar{T}\in\mathbb{R}^n$ and $\bar{c}\in \mathbb{R}^{40n}$

============

\begin{align}
T_i = \bar{T}[N]
\end{align}


=============


\pr{Problem} The overall problem is:
\begin{align}
J^{*} &= \min_{\bar{T},\bar{c}} T_N\\
\nonumber & P(x_t\in \mathbb{X}_{obs}) < \epsilon_1, \forall~t \in [0,T_N]\\
\nonumber & P(x_T\in \mathbb{X}_{goal}) > 1-\epsilon_2 \\
\nonumber & u_{min} < u_t < u_{max}, \forall~t \in [0,T_N]
\end{align}

\rohan{FIRM nodes to be created in which space?}
\rohan{EKF uses IMU and not the same process}


\begin{align}
node^i = ?
\end{align}

\begin{align}
T^{ij} = g_{time}(node^i,node^j)
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Future work}
\begin{enumerate}
    \item Closed-loop controller for quadcopter
\end{enumerate}

\printbibliography

\end{document}
% marco pavone chance constraint dp on graph
% RHC satisfaction
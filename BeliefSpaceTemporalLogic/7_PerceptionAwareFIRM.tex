\documentclass[conference]{IEEEtran}
\usepackage{standalone}
\usepackage{times}
\usepackage{float}
\usepackage{biblatex}
\addbibresource{7_refs.bib}


\input{TemplateFiles/def.tex}
\input{TemplateFiles/inc}

% numbers option provides compact numerical references in the text. 

\pdfinfo{
   /Author (Homer Simpson)
   /Title  (Robots: Our new overlords)
   /CreationDate (D:20101201120000)
   /Subject (Robots)
   /Keywords (Robots;Overlords)
}

% Table caption wrangling
\usepackage{etoolbox}
\makeatletter
\patchcmd{\@makecaption}
  {\scshape}
  {}
  {}
  {}
\makeatletter
\patchcmd{\@makecaption}
  {\\}
  {.\ }
  {}
  {}
\makeatother

\newcommand{\Ali}[1]{{\color{green} Ali: #1}}
\newcommand{\cristi}[1]{{\color{orange} Cristi: #1}}
\newcommand{\rohan}[1]{{\color{blue} Rohan: #1}}
\allowdisplaybreaks[1]

\begin{document}

% paper title
%\title{\large From Mission Specification to Safe Control Logic Under Uncertainty:\\ Application to Mars Copter-Rover Navigation-Coordination}

\title{\huge Vision Aware FIRM}

\author{Rohan, Ali, Kamak, Cristi, Petter, Sofie, Richard, Murray, Aaron Ames}

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}
\end{abstract}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Related work}
\cite{achtelik2014motion}

\cite{costante2018exploiting}

\cite{perception-aware-planning} 

\cite{Perception-Aware-Multiobjective-Search}

\cite{MapQualityEvaluation}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Problem Definition}
\subsection{General}
For state $x$ and control input $u$ motion and observation model are defined as follows:
\begin{align}
x_{k+1} &= f(x_k, u_k, w_k), w_k \sim p(w_k|x_k,u_k) \\
z_k &= h(x_k, v_k), v_k \sim p(v_k|x_k)
\end{align}

A belief state $b$ is a posterior distribution over all past actions and observations and it's evolution is as follows:
\begin{align}
    b_{k+1} &= p(x_{k+1}|z_{0:k+1}, u_{0:k}) \\
            &= \tau(b_k,u_k,z_{k+1})
\end{align} 

A policy $\pi : \mathbb{B} \to \mathbb{U}$ is a mapping from belief to a control input.

\pr{Problem} The overall problem is:
\begin{align}
\pi^{*} &= \arg\min \mathbb{E}\\
\nonumber & \Pr(x\in F) < \epsilon \\
\nonumber & u_{min} < u_i < u_{max}
\end{align}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Motivation}
Talk about degenerate configurations with figures.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Sensor Model}

Let $P \in \mathbb{R}^{3}$ represent a 3-d point, $p \in \mathbb{R}^2$ represent represent a point in the image space and $\pi_\theta:\mathbb{R}^3\to\mathbb{R}^2$ be the camera projection model assuming that the intrinsic camera parameters are known and $\theta$ represents the pose of the camera in the world frame.

The equation below projects a point $P$ in the world frame to image space of $k^{th}$ camera frame:
\begin{equation} p=\pi_\theta(^{w}P) \end{equation}
We can retrieve the 3-d point in the world frame from a point in the image space and known depth, using: 
\begin{equation} ^{w}P=\pi^{-1}_\theta(p,d) \end{equation}

The sensor model is obtained by using the following equation, where $\Sigma_o$ is covariance of the image noise (estimation of location of the feature points).
\begin{equation}
     z_p = h(\theta,v)=
     \pi_\theta(\pi^{-1}_{\theta_{kf}}(p,d)) + v,~~~ v\sim \mathcal{N}(0,\Sigma_{o})
     \label{eq:ObsModel}
\end{equation}


The pose of the camera $\theta$ can be estimated by minimizing the re-projection error, as shown in the equation below. Where, $\theta_{kf}$ represents the pose of the keyframe and $p_z$ represents the measure location of the feature point in the image space.
\begin{equation}
     \theta = \underset{\theta}{\arg\min}~\Sigma ||z_{p_i} - \pi_\theta(\pi^{-1}_{\theta_{kf}}(p_i,d_i))||^2_{\Sigma_o}
\end{equation}

Information $\mathcal{I}$ can be found using the following equation:
\begin{equation}
     \mathcal{I} = J^{T}\Sigma^{-1}_{o}J
\end{equation}
for
\begin{equation}
     J = \frac{dh}{d\theta}
\end{equation}

Advantages:
\begin{itemize}
    \item Computationally more efficient than direct or homography based approaches.
    \item Does not require homography assumptions like planar scenes, etc.
\end{itemize}

Challenges:
\begin{itemize}
    \item Efficiently finding all the feature points in the field for a given camera pose $\theta$.
    \item Acquiring set of keyframes from an elevation map of the environment.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Planning}\label{sec:planning}

\pr{Cost Graph in Belief Space}

\pr{Dynamic-aware Local Planning in Belief Space}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Experiment}\label{sec:experiment}

\subsection{Rover }
The dynamics of the rover are given by unicycle model:
\begin{equation}
    \begin{bmatrix}
        x(t+1) \\
        y(t+1) \\
        \psi(t+1)
    \end{bmatrix} = \begin{bmatrix}x(t) + v \cos(\psi(t)) \delta{t}\\ y(t) + v \sin(\psi(t)) \delta{t}\\ \psi(t) + \omega \delta{t} \end{bmatrix} + w,
\end{equation}
where position of the rover is given by $(x,y)$, its heading is given by $\psi$ and it is corrupted by Gaussian noise $w \sim \mathcal{N}(0,\Sigma)$. \\
\rohan{Do we incorporate roll and pitch in the dynamics?}

\subsection{Copter}
\pr{Dynamics} \\
% Better localization for map creation or avoiding obstacle
The dynamics of the quadrotor are given by the following equations:
\begin{gather}
m\ddot{x} = mge_{3} - fRe_{3} \\
\dot{R} = R\hat{\Omega} \\
J\dot{\Omega} + \Omega \times J\Omega = M 
\end{gather}
where the state of the copter is given by position, velocity, acceleration $x, \dot{x}, \ddot{x} \in \mathbb{R}^3$, orientation $R \in SO(3)$ and angular velocity $\Omega \in \mathbb{R}^3$.
Control input is the total thrust $f \in \mathbb{R}$ and moment $M \in \mathbb{R}^3$.
Parameters of the system are mass $m$, intertia matrix $J$ and gravity $g$.
Hat map $\hat{.}: \mathbb{R}^3 \to \mathfrak{so}(3)$ is defined by the condition $a \times b = \hat{a}b$ where $a,b\in \mathbb{R}^3$, and $\times$ is the vector cross-product operator.

Since the system is differentially flat, we can find a control input $u(t)$ and state $\boldsymbol{x}(t)$ for a given trajectory of the copter in the flat space $[x, y, z, \psi] \in \mathbb{R}^4$.

\pr{Problem} The overall problem is:
\begin{align}
\pi^{*} &= \arg\min \mathbb{E}\sum_{k=0}^n T_k\\
\nonumber & \Pr(x\in F) < \epsilon \\
\nonumber & u_{min} < u_i < u_{max}
\end{align}
\rohan{Where do we want to add noise in the dynamics?} \\
\rohan{What is the local controller? LQG won't be robust if we linearise the attitude} \\
\rohan{What representation do we use for the trajectories?} 
\rohan{Currently we can execute only execute trajectories which are a sequence of 9th order polynomials}
\printbibliography

% marco pavone chance constraint dp on graph
% RHC satisfaction

\end{document}
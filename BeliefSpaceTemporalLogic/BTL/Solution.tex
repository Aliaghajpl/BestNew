%\section{Preliminaries}
%\label{sec:preliminaries}
%In this section, we provide a brief overview of
%the main ideas and methods from sampling-based planning,
%control theory, and formal methods used in the solution proposed
%in Section~\ref{sec:solution} to solve Problem~\ref{pb:mpp}.
%For detailed information on these notions,
%see~\cite{Baier08,Lav06,Bertsekas2012}.% and the references therein.

%\subsection{Sampling-based planners}
%\label{sec:prelim-rrg}
%Sampling-based algorithms are a class of randomized algorithms
%developed for path and motion planning~\cite{Lav06}.
%In short, a sampling-based algorithm 
%iteratively grows a graph $\TS$ in the state space in which nodes are individual states and edges correspond to motion primitives that drive the robot from state to state.
%%grows a graph by adding
%%randomly sampled states. 
%However, the extension procedure
%is biased towards exploration of uncovered regions of the
%state space.
%Sampling-based algorithms are built using a set of primitive
%functions that are assumed to be available.
%The primitive functions we assume to be available are:
%\begin{itemize}
%  \item $sample(\CA{X})$ generates random states
%from a distribution over the state space $\CA{X}$,
%  \item $nearest(x_r, \TS)$ returns the closest state
%in $\TS$ to the state $x_r$ using the metric defined on
%$\CA{X}$,
%  \item $near(B_n, \TSX, \#Nbrs)$ returns the closest $\#Nbrs$
%states in $\TSX$ to $B_n$, and
%  \item $steer(x_i, x_t)$ returns a state obtained by
%attempting to drive the system from $x_i$ towards $x_t$.
%\end{itemize}
%For simplicity, in this paper we assume that the $steer()$
%function is always able to produce a state that is closer
%to $x_t$ that $x_i$ with respect to the metric defined on
%$\CA{X}$.
%Using these primitive functions, an extension procedure
%$extend(\CA{X}, \TS)$ of the motion abstraction graph
%can be defined as:
%\begin{enumerate}
%  \item generate a new sample $x_r \asgn sample(\CA{X})$,
%  \item find nearest state $x_u \asgn nearest(x_r, \TS)$, and
%  \item drive the system towards the random sample
%$x_n \asgn steer(x_u, x_r)$.
%%
%\end{enumerate}
%For more details about the sampling-based algorithms
%and the primitive functions and their implementations
%see~\cite{Lav06,KF-IJRR11,VaBe-IROS-2013}.
%
%\subsection{Linear quadratic Gaussian control}
%\label{sec:lqg}
%
%Given an LTI system~\eqref{eq:LTI} with linear observation model~\eqref{eq:linearObservations},
%we can design an optimal controller
%called Linear Quadratic Regulator (LQR) of the form
%\begin{align}
%u = -L (\hat{x}_k - x^d)
%\end{align}
%%
%where $L$ is the stationary feedback gain,
%$\hat{x}_k$ is the {\it a posteriori} state estimate
%computed by the Kalman filter,
%$x^d$ is the fixpoint of the LTI system.
%The LQR controller minimizes the following cost function
%\begin{equation}
%\label{eq:lqr-cost}
%J(u) = \BB{E}\left[ \sum_{k \geq 0} (\hat{x}_k - x^d)^T W_x (\hat{x}_k - x^d) + u_k^T  W_u u_k\right],
%\end{equation}
%where $W_x$ and $W_u$ are positive-definite weight matrices.
%The feedback gain $L$ is generated by solving a discrete
%algebraic Riccatti equation (DARE).
%The feedback gain $L$ is generated by solving the discrete
%algebraic Riccatti equation (DARE)
%\begin{equation}
%\label{eq:lqr-dare}
%S = W_x + A^T S A = A^T S B (B^T S B + W_u)^{-1} B^T S A
%\end{equation}
%and setting the gain as
%\begin{equation}
%\label{eq:lqr-gain}
%L = (B^T S B + W_u)^{-1} B^T S A
%\end{equation}

%If the process and observation noise are
%zero-mean Gaussian processes, then the LQR
%controller is optimal with respect to the cost
%function~\eqref{eq:lqr-cost}. Moreover,
%the controller can be designed independently from
%the observer.
%The LQR controller together with the KF
%form a Linear Quadratic Gaussian (LQG) controller.
%
%The stationary covariance matrix may be computed
%as follows~\cite[Lemma 2]{Agha14},~\cite{Bertsekas2012}:
%\begin{lemma}
%%If Assumption~\ref{assump:lti} holds, then the stationary
%If the LTI system~\eqref{eq:LTI}-\eqref{eq:linearObservations} is observable and $C$ is full-rank, then the stationary
%covariance matrix can be computed as
%\begin{equation}
%\label{eq:cov-infty}
%P^\infty = P^\infty_- -  P^\infty_- C^T ( C P^\infty_- C^T + R )^{-1} C P^\infty_-,
%\end{equation}
%where $P^\infty_-$ is the unique symmetric positive-definite
%solution of the DARE
%\begin{equation*}
%P^\infty_- = Q + A P^\infty_- A^T - A P^\infty_- C^T (C P^\infty_- C^T + R)^{-1} C P^\infty_- A^T .
%\end{equation*}
%\end{lemma}

%\subsection{Linear Temporal Logic and Rabin Automata}
%\subsection{Rabin Automata}

%A Linear Temporal Logic (LTL) formula over a set of atomic propositions $\Pi$
%is defined using standard Boolean operators, $\notltl$ (negation),
%$\andltl$ (conjunction) and $\orltl$ (disjunction), and
%temporal operators, $\Next$ (next), $\Until$ (until), $\Event$ (eventually),
%$\Always$ (always).
%The semantics of LTL formulae over $\Pi$ are given with respect to infinite words over $2^\Pi$.
%In this paper, we consider a particular fragment of LTL, called LTL$_{-\Next}$~\cite{Baier08},
%which does not include the $\Next$ (next) operator.
%LTL$_{-\Next}$ is useful in defining specifications which are independent of the number of
%consecutive repetitions of symbols or stutter-invariant formulae~\cite{Baier08}.
%Formal definitions for the LTL syntax, semantics, and model checking can be found in~\cite{Baier08}.

%\begin{definition}[Rabin Automaton]
%A (deterministic) Rabin automaton is a tuple $\RA = (S_\RA, s_0^\RA, \Sigma, \delta, \Omega_\RA)$, where %:
%$S_\RA$ is a finite set of states, $s_0^\RA \in S_\RA$ is the initial state,
%$\Sigma$ is the input alphabet,
%$\delta : S_\RA \times \Sigma \ra S_\RA$ is the transition function, and
%$\Omega_\RA$ is a set of tuples $(\CA{F}_i, \CA{B}_i)$ of disjoint subsets
%of $S_\RA$ which correspond to good ($\CA{F}_i$) and bad ($\CA{B}_i$) states.
%%\begin{itemize}
%%    \item $S_\RA$ is a finite set of states;
%%    \item $s_0^\RA \in S_\RA$ is the initial state;
%%    \item $\Sigma$ is the input alphabet;
%%    \item $\delta : S_\RA \times \Sigma \ra S_\RA$ is the transition function;
%%    \item $\Omega_\RA$ is a set of tuples $(\CA{F}_i, \CA{B}_i)$ of disjoint subsets of $S_\RA$ which correspond to good ($\CA{F}_i$) and bad ($\CA{B}_i$) states.
%%\end{itemize}
%\end{definition}
%
%A transition $s' = \delta(s, \sigma)$ is also denoted by $s \ras{\sigma}_\RA s'$.
%A trajectory of the Rabin automaton $\BF{s} = s_0 s_1 \ldots$ is generated by
%an infinite sequence of symbols $\BS{\sigma} = \sigma_0 \sigma_1 \ldots$ if
%$s_0 = s_0^\RA$ is the initial state of $\RA$ and $s_k \ras{\sigma_k}_\RA s_{k+1}$
%for all $k \geq 0$.
%Given a state trajectory $\BF{s}$ we define $\vartheta_\infty(\BF{s}) \subseteq S_\RA$
%as the set of states which appear infinitely many times in $\BF{s}$.
%An infinite input sequence over $\Sigma$ is said to be accepted by a Rabin automaton
%$\RA$ if there exists a tuple $(\CA{F}_i, \CA{B}_i) \in \Omega_\RA$ of good and bad
%states such that the state trajectory $\BF{s}$ of $\RA$ generated by $\BS{\sigma}$
%intersects the set $\CA{F}_i$ infinitely many times and the set $\CA{B}_i$ only finitely
%many times.
%Formally, this means that $\vartheta_\infty(\BF{s}) \cap \CA{F}_i \neq \emptyset$
%and $\vartheta_\infty(\BF{s}) \cap \CA{B}_i = \emptyset$.
%
%%It is shown in~\cite{Baier08} that for every LTL formula $\phi$
%%over $\Pi$ there exists a DRA $\RA$ over alphabet $\Sigma = \spow{\Pi}$ such that
%%$\RA$ accepts all and only those infinite sequences over $\Pi$ that satisfy $\phi$.
%{\color{blue} [Move to GDTL or solution sections] 
%There exist efficient algorithms that translate LTL formulae into Rabin automata~\cite{klein2006}.}


\section{Solution}
\label{sec:solution}

In our approach, we use sampling-based  techniques to generate paths throughout the state space.
Local controllers drive the systems along these paths and stabilize at key points.
The closed-loop behavior of the system induces paths in the belief space.
The FIRM describes the stochastic process that generates these paths.
%By combining the FIRM with a Rabin automaton, we are able to build
%an MDP that allows us to evaluate whether sample paths satisfy a GDTL formula.
We build an MDP by combing the FIRM with a Rabin automaton which then allows us to check if sample paths satisfy a GDTL formula.
We compute transition probabilities and intersection probabilities
(probability of intersecting a good or bad set from the Rabin automaton's
acceptance condition) for each edge in this structure.
We use dynamic programming to find the policy in this structure that maximizes the probability of satisfying the formula.
The resulting policy can then be translated to a non-stationary switched local controller that approximates the solution to Pb.~\ref{pb:mpp}.
An important property of the proposed solution is that all operations
are incremental with respect to the size of the FIRM.
Note that the proposed solution may be applied to nonlinear
systems whose linearizations around random samples in the state
space satisfy the assumptions in Sec.~\ref{sec:motion}.
The details of our solution Alg.~\ref{alg:compute-mdp} are presented below.

%{\color{blue}[This is only used in Alg. 1. If we trim that algorithm, we should check if this text is still necessary.] }
%Let $(x, P) \in \CA{G}$ be a belief state. 
%We denote by $N_\delta(x, P) = \{ b \in \CA{G} \,|\, \norm{b - (x, P)}_\CA{G} \leq \delta \}$ the uncertainty ball of radius $\delta$ in the belief space centered at $(x, P)$, where $\norm{\cdot}_\CA{G}$ over $\CA{G}$ is a suitable norm in $\CA{G}$.

%In the following sections, the system's dynamics will be denoted by
%the pair $(f, h)$, where $f(x, u, w) = Ax + Bu + w$ is the motion model,
%and $h(x, v) = Cx + v$ is the observation model.
%$(f, h)$

\subsection{Sampling-based algorithm}

We propose a sampling-based algorithm to solve Pb.~\ref{pb:mpp}
that overcomes the curse of dimension and history generally associated with POMDPs.
In short, a sampling-based algorithm iteratively grows a graph $\TS$
in the state space, where nodes are individual states, and edges 
correspond to motion primitives that drive the system from state to state~\cite{Lav06}.
The extension procedure is biased towards exploration of
uncovered regions of the state space.
Similar to~\cite{Agha14}, we adapt sampling-based
methods to produce finite abstractions (e.g., graphs) of the belief space.
Alg.~\ref{alg:compute-mdp} incrementally constructs
a transition system $\TS = (\TSX, B_0, \Delta_\TS, \CA{C}_\TS)$,
where the state space $\TSX$ is composed of
belief nodes, i.e., bounded hyper-balls in $\CA{G}$,
$ \Delta_\TS$ is the set of transitions, and $\CA{C}_\TS$ is a set
of controllers associated with edges.
%subsets of $\CA{G}$.
%In the proposed algorithm, belief nodes are hyper-balls in the
%belief space.
The center of a belief node is a belief state $b=(x, P^\infty)$,
where the mean $x$ is obtained through random sampling of
the system's state space, and $P^\infty$ is the stationary covariance.
The initial belief node is denoted by $B_0$.

Sampling-based algorithms are built using a set of primitive
functions that are assumed to be available:
%The primitive functions we assume to be available are:
\begin{itemize}
  \item $sample(\CA{X})$ generates random states
from a distribution over the state space $\CA{X}$,
  \item $nearest(x^r, \TS) = \arg\min_{x^u}\{ \normeucl{x^r-x^u} \,|\, \exists P^u \wedge N_\delta(x^u, P^u) \in \TSX \}$
  returns the mean $x^u$ of a belief node's center in $\TS$ such that $x^u$ is closest
  to the state $x^r$ using the metric defined on $\CA{X}$,
  \item $near(B_n, \TSX, \gamma)$ returns the closest $\gamma$
belief nodes in $\TSX$ to $B_n$ with respect to the distance between their centers
induced by $\norm{\cdot}_\CA{G}$, and
  \item $steer(x^i, x^t)$ returns a state obtained by
attempting to drive the system from $x^i$ towards $x^t$.
\end{itemize}
%For simplicity, in this paper we assume that the $steer()$
%function is always able to produce a state that is closer
%to $x_t$ that $x_i$ with respect to the metric defined on
%$\CA{X}$.
Using these primitive functions, an extension procedure
$extend(\CA{X}, \TS)$ of the transition system $\TS$
can be defined as:
\begin{enumerate}
  \item generate a new sample $x^r \asgn sample(\CA{X})$,
  \item find nearest state $x^u \asgn nearest(x^r, \TS)$, and
  \item drive the system towards the random sample
$x^n \asgn steer(x^u, x^r)$.
\end{enumerate}
For more details about sampling-based algorithms,
primitive functions and their implementations
see~\cite{Lav06,KF-IJRR11,VaBe-IROS-2013}.

Transitions are enforced using local controllers which are stored
in $\CA{C}_\TS$. i.e., we assign to each edge
$e \in \Delta_\TS$ a local controller $ec_e \in \CA{C}_\TS$.
Under the assumptions of our model~\cite{Agha14}, the local controllers
are guaranteed to stabilize the system to belief nodes along a path in finite time.
Thus we abstract the roadmap to a deterministic system.
In Alg.~\ref{alg:compute-mdp}, local controllers are generated
using the method $localController()$.
The design of the node controllers is presented Sec.~\ref{sec:caseStudy}. 
%However, when we plan to compute a policy to enforce the specification,
%we must compute the probability of invalidating the specification
%before stabilizing at a subsequent belief node.
%For this reason, we annotate the edges of the product automaton with
%``failure probabilities" (intersection) and transform it to an MDP.
%The intersection probabilities at the same time as the transition
%probabilities between the states of the MDP, i.e., pairs of belief nodes
%and DRA states.

The algorithm checks for the presence of a satisfying path using
a deterministic Rabin automaton (DRA) $\RA$ that is computed from
the GDTL specification using an intermediate linear temporal logic (LTL)
construction~\cite{JonesDTL2013}.
There exist efficient algorithms that translate LTL formulae into Rabin automata~\cite{klein2006}.
We denote the set of predicates in GDTL formula $\phi$ as $F_\phi$.

\begin{definition}[Rabin Automaton]
A (deterministic) Rabin automaton is a tuple $\RA = (S_\RA, s_0^\RA, \Sigma, \delta, \Omega_\RA)$, where %:
$S_\RA$ is a finite set of states, $s_0^\RA \in S_\RA$ is the initial state,
$\Sigma\subseteq 2^{F_\phi}$ is the input alphabet,
$\delta : S_\RA \times \Sigma \ra S_\RA$ is the transition function, and
$\Omega_\RA$ is a set of tuples $(\CA{F}_i, \CA{B}_i)$ of disjoint subsets
of $S_\RA$ which correspond to good ($\CA{F}_i$) and bad ($\CA{B}_i$) states.
%\begin{itemize}
%    \item $S_\RA$ is a finite set of states;
%    \item $s_0^\RA \in S_\RA$ is the initial state;
%    \item $\Sigma$ is the input alphabet;
%    \item $\delta : S_\RA \times \Sigma \ra S_\RA$ is the transition function;
%    \item $\Omega_\RA$ is a set of tuples $(\CA{F}_i, \CA{B}_i)$ of disjoint subsets of $S_\RA$ which correspond to good ($\CA{F}_i$) and bad ($\CA{B}_i$) states.
%\end{itemize}
\end{definition}

A transition $s' = \delta(s, \sigma)$ is also denoted by $s \ras{\sigma}_\RA s'$.
A trajectory of the Rabin automaton $\BF{s} = s_0 s_1 \ldots$ is generated by
an infinite sequence of symbols $\BS{\sigma} = \sigma_0 \sigma_1 \ldots$ if
$s_0 = s_0^\RA$ is the initial state of $\RA$ and $s_k \ras{\sigma_k}_\RA s_{k+1}$
for all $k \geq 0$.
Given a state trajectory $\BF{s}$ we define $\vartheta_\infty(\BF{s}) \subseteq S_\RA$
as the set of states which appear infinitely many times in $\BF{s}$.
An infinite input sequence over $\Sigma$ is said to be accepted by a Rabin automaton
$\RA$ if there exists a tuple $(\CA{F}_i, \CA{B}_i) \in \Omega_\RA$ of good and bad
states such that the state trajectory $\BF{s}$ of $\RA$ generated by $\BS{\sigma}$
intersects the set $\CA{F}_i$ infinitely many times and the set $\CA{B}_i$ only finitely
many times.
Formally, this means that $\vartheta_\infty(\BF{s}) \cap \CA{F}_i \neq \emptyset$
and $\vartheta_\infty(\BF{s}) \cap \CA{B}_i = \emptyset$.

%A product MDP $\PA$
%between the TS $\TS$ and the DRA $\RA$ is
%maintained in an incremental fashion.
%The MDP captures motion and satisfaction at the same time, and 
%is used to compute the maximum probability satisfying policy $\mu^*$
%on the finite abstraction $\TS$.

\begin{algorithm}[!htb]
\caption{$ConstructTS(x_0,\phi,\varepsilon)$}
\label{alg:compute-mdp}
\DontPrintSemicolon
\KwIn{initial state $x^0$, GDTL specification $\phi$, and lower bound $\varepsilon$}
%\KwIn{\color{blue} $(f, h)$ -- model of the robot (motion and sensing)}
%\KwIn{$\phi$ -- GDTL specification}
%\KwIn{$\varepsilon$ -- lower bound probability of satisfying policy}
\KwOut{belief transition system $\TS$, product MDP $\PA$, and satisfying policy $\mu^*$}
%\KwOut{$\PA$ -- product MDP}
%\KwOut{$\mu^* : S_\PA \to S_\PA$ -- satisfying feedback policy on $\PA$ w/ probability at least $\varepsilon$}
\BlankLine

convert GDTL formula $\phi$ to LTL formula $\varphi$ over the set of atomic propositions $\AP=F_\phi$\;
compute DRA $\RA=(S_\RA, s_0^\RA, \spow{\AP}, \delta, \Omega_\RA)$ from $\varphi$\;
$ec_0, P^\infty_0 \asgn localController(x^0)$\;
$B_0 \asgn N_\delta(x^0, P^\infty_0)$\;
$e_0 = (B_0, B_0)$\;
$\pi^{S_\RA}_0, \pi^{\Omega_\RA}_0 \asgn computeProb(e_0, s_0, ec_0, \RA)$\;
initialize belief TS $\TS = (\TSX = \{B_0\}, B_0, \Delta_\TS = \{e_0\}, \CA{C}_\TS = \{ (e_0, ec_0)\})$\;
construct product MDP $\PA = \TS \times \RA = (S_\PA = \TSX \times S_\RA, (B_0, s_0),
Act=\TSX, \delta_\PA = \{ \pi^{S_\RA}_0 \}, \Omega_\PA = \{ \pi^{\Omega_\RA}_0 \})$\;

\For{$index = 1$ \KwTo $N$}{
     $x^n \asgn extend(\CA{X}, \TS)$  \;
%    $x_r \asgn sample(\CA{X})$\;
%    $x_u \asgn nearest(x_r, \TS)$\;
%    $x_n \asgn steer(x_u, x_r)$\;
    $ec_n, P^\infty_n \asgn localController(x^n)$\;
    $B_n \asgn N_\delta(x^n, P^\infty_n)$\;
    $\CA{N}_n \asgn near(B_n, \TSX, \gamma)$\;
    $\begin{aligned}\Delta_n &\asgn \{ (B_i, B_n) | x^n = steer(x^i, x^n), B_i \in \CA{N}_n\}\\
           &\quad {} \cup \{ (B_n, B_i) | x^i = steer(x^n, x^i), B_i \in \CA{N}_n \} \end{aligned}$\;
    $\TSX \asgn \TSX \cup \{B_n\}$, $\Delta_\TS \asgn \Delta_\TS \cup \Delta_n$\;
    $S_\PA \asgn S_\PA \cup (\{ B_n \} \times S_\RA)$\;
    \ForEach{$e=(B_u, B_v) \in \Delta_n$}{
%        $ec_e \asgn edgeController(B_u, B_v, nc_v)$\;
        $\CA{C}_\TS \asgn \CA{C}_\TS \cup \{ (e, ec_v)\}$\;
        \ForEach{$s_u \in S_\RA$ s.t. $(B_u, s_u) \in S_\PA$}{
            $\pi^{S_\RA}_e, \pi^{\Omega_\RA}_e \asgn computeProb(e, s_u, ec_v, \RA)$\;
            $\delta_\PA \asgn \delta_\PA \cup \{ \pi^{S_\RA}_e\}$\;
            $\Omega_\PA \asgn \Omega_\PA \cup \{ \pi^{\Omega_\RA}_e \}$\;
        }
%        {\color{blue} compute edge cost (?)}\;
    }
    $\Delta^n_\PA = \{ (p, p') \in \Delta_\PA \,|\, \proj{(p, p')}{\TS} \in \Delta_n \}$\;
    \ForEach(\tcp*[h]{update ECs}){$(\CA{F}_i, \CA{B}_i) \in \Omega_\RA$}{
        $\begin{aligned}\Gamma_i &= \{ (p, p') \in \Delta^n_\PA \,|\, \pi^{\Omega_\RA}(e, \CA{F}_i) = 0 \\
        &\qquad {} \wedge \pi^{\Omega_\RA}(e, \CA{B}_i) > 0, e=\proj{(p, p')}{\TS} \} \end{aligned}$\;
        $c_i.update(\Delta^n_\PA \setminus \Gamma_i)$\;
    }

%    {\color{blue} update SCCs' reach and stay probabilities}\;
    \If{$existsSatPolicy(\PA)$}{
        solve DP~\eqref{eq:dp} and compute policy $\mu^*$ with probability of satisfaction $p$\;
        \lIf{$p \geq \varepsilon$}{
            \Return $(\TS, \PA, \mu^*)$
        }
    }
}
\Return $(\TS, \PA, \emptyset)$
\end{algorithm}

%\begin{algorithm}
%\caption{$extend(\TS)$}
%\label{alg:extend}
%\DontPrintSemicolon
%\KwIn{$\TS$ -- belief transition system}
%\KwOut{$x_n$ -- random sample}
%\KwOut{$\Delta_n$ -- set of transitions}
%\BlankLine
%
%{\color{blue} TODO:}\;
%$done \asgn \False$\;
%\Repeat{$done$}{
%	
%}
%\Return $(x_n, \Delta_n)$
%\end{algorithm}

%\subsection{Local controllers}
%
%Similar to FIRM~\cite{Agha14}, we use local controllers
%to drive the system between the belief nodes of the
%transition system $\TS$, and to stabilize the belief about
%the system's state around the destination nodes.
%We assign to each node $B_i \in \TSX$ in the transition
%system a local controller $nc_i$, which drives the belief
%into $B_i$.
%We also associate with each transition
%$e = (B_u, B_v) \in \Delta_\TS$ an edge controller $ec_e$.
%The edge controller may simply be the node
%controller $nc_v$ associated with the destination node $B_v$.
%However, as suggested in~\cite{Agha14},
%two-stage local controllers are used instead.
%In the first stage, a
%pre-computed nominal trajectory is tracked until the system's state
%gets close to the destination belief node.
%Then, the controller switches to the node controller
%associated with the destination belief node.
%
%The design of the node controllers is presented Sec.~\ref{sec:caseStudy}. 
%For brevity, we omit the details of the tracking controller.
%{\color{blue} For more details about local controllers and examples using
%linear quadratic Gaussian techniques see~\cite{Agha14}.
%}
%It is shown in~\cite[Lemma 3]{Agha14} that these
%controllers can reach their destination belief nodes
%in finite (mean) time.

%\subsection{GDTL to LTL}
%\label{sec:gdtl2ltl}
%
%The predicates considered in GDTL
%are defined over the belief space $\CA{G}$ and
%describe sets in this space. However, because the
%uncertainty is separate from the temporal ordering
%of the satisfaction of the predicates, the sets
%determined by the predicates are independent
%of the position of a belief state $b^i$ in
%a belief word $\BF{b}$.
%As a consequence, we can convert a GDTL formula
%into an LTL formula.
%
%Denote $\CA{G}_f = \{ b\in \CA{G} \ |\ f(b) \leq 0\}$,
%where $f \in \CA{F}(\CA{G}, \BB{R})$.
%
%\begin{definition}[LTL Equivalent]
%\label{def:gdtl2ltl}
%Let $\phi$ be a GDTL formula and $F_\phi$ be the set
%of all predicates in $\phi$. Let $\AP$ be a finite set such
%that $\card{\AP} = \card{F_\phi}$ and a bijective
%map $\widetilde{\ }: F_\phi \to \AP$.
%Consider the LTL formula $\varphi$, where
%each predicate in $F_\phi$ is substituted by its associated
%atomic proposition in $\AP$ using the map
%$\widetilde{\ }$.
%The semantics of $\varphi$ are given with
%respect to infinite words in $\CA{G}^\omega$.
%Satisfaction of an atomic proposition
%$\BF{b} \models \widetilde{p}$ is interpreted as
%$b^0 \in \CA{G}_f$, where $p=(f \leq 0)\in F_\phi$.
%The Boolean and temporal operators retain
%their usual meaning.
%\end{definition}

\subsection{Computing transition and intersection probability}

Given a transition $e=(B_u, B_v)$ and its associated local controller $ec_e$,
Alg.~\ref{alg:compute-prob} computes the transition distribution from
an initial DRA state $s_u$ to a some random DRA state, and a set
of intersection distributions associated with each pair $(\CA{F}_i, \CA{B}_i)$
of the acceptance set of $\RA$.
These distributions are hard to compute analytically. Therefore, we
estimate them from sample trajectories of the closed-loop system
enforcing edge $e$.
In Alg.~\ref{alg:compute-prob}, the function $sampleBeliefSet(S)$
returns a random sample from a uniform distribution over the
belief set $S$.

\begin{algorithm}
\caption{$computeProb(e=(B_u, B_v), s_u, ec_e, \RA)$}
\label{alg:compute-prob}
\DontPrintSemicolon
\SetKwInOut{KwParam}{Parameter}
\KwIn{transition between belief nodes $e=(B_u, B_v)$, starting DRA state $s_u$, controller enforcing $e$ $ec_e$, and deterministic Rabin automaton $\RA$}
%\KwIn{$s_u$ -- starting DRA state}
%\KwIn{$ec_e$ -- controller enforcing $e$}
%\KwIn{$\RA$ -- deterministic Rabin automaton}
\KwOut{transition distribution $\pi^{S_\RA}$, and intersection distribution $\pi^{\Omega_\RA}$ }
%\KwOut{$\pi^{\Omega_\RA}$ -- reach/avoid distribution}
\KwParam{$NP$ -- number of particles}
\BlankLine

$t \asgn \BF{0}_{\card{S_\RA}, 1}$\;
$ra_i \asgn \BF{0}_{3, 1}$, $\forall (\CA{F}_i, \CA{B}_i) \in \Omega_\RA$\;
\For{$p=1:NP$}{
    $b_u \asgn sampleBeliefSet(B_u)$\;
    $b^{0:T} \asgn ec_e(b_u)$\;
    \For{$k = 0$ \KwTo $T-1$}{
        $\sigma_k \asgn \{ f \,|\, f(b^k) \leq 0, \forall f \in F_\phi \}$\;
    }
    $\BF{s} = s_{0:T} \asgn (s_u \ras{\sigma_{0:T-1}} s_T)$\;
    $t[s_T] \asgn t[s_T] + 1$\;
    \For{$(\CA{F}_i, \CA{B}_i) \in\card{\Omega_\RA}$}{
        \lIf{$\CA{F}_i \cap \BF{s} \neq \emptyset$}{
            $ra_i[1] \asgn ra_i[1] + 1$
        }
        \lIf{$\CA{B}_i \cap \BF{s} \neq \emptyset$}{
            $ra_i[2] \asgn ra_i[2] + 1$
        }
        \lIf{$(\CA{F}_i \cup \CA{B}_i)\cap \BF{s} = \emptyset$}{
            $ra_i[3] \asgn ra_i[3] + 1$
        }
    }
}
\Return $\left( \pi^{S_\RA} = \frac{t}{NP}, \pi^{\Omega_\RA} = \left\{ \frac{ra_i}{NP} \,|\, 1\leq i\leq \card{\Omega_\RA} \right\} \right)$
\end{algorithm}

The distribution $\pi^{S_\RA}$ captures the probability that
$s_v$ is the state of $\RA$ at the end of closed-loop
trajectory generated by controller $ec_e$ to steer the system
from belief node $B_u$ and DRA state $s_u$ to belief node $B_v$:
$\pi^{S_\RA} = Pr[s_v \, |\, e, s_u, ec_e]$,
where $s_v \in S_\RA$, $s_{u} \ras{\sigma_{0:T-1}} s_v$,
$b^{0:T} = ec_e(b_u)$, $b_u \in B_u$, and
$\sigma_k \asgn \{ f \,|\, f(b^k) \leq 0, \forall f \in F_\phi \}$.

Each intersection distribution represents the probability that edge $e$
intersects $\CA{F}_i$, $\CA{B}_i$ or neither, where
$(\CA{F}_i, \CA{B}_i) \in \Omega_\RA$, and the controller $ec_e$
was used to drive the system along the edge $e$ starting from
the DRA state $s_u$:

{\footnotesize
\begin{equation}
\pi^{\Omega_\RA} = \left\{\left.
\begin{cases}
Pr[\BF{s}\cap \CA{F}_i \, |\, e, s_u, ec_e]\\
Pr[\BF{s}\cap \CA{B}_i \, |\, e, s_u, ec_e]\\
Pr[\BF{s}\cap (\CA{F}_i \cup \CA{B}_i) \, |\, e, s_u, ec_e]
\end{cases}
\,\right|\, \forall (\CA{F}_i, \CA{B}_i) \in \Omega_\RA \right\}
\end{equation}
}%
For convenience, we use the following notation
$\pi^{\Omega_\RA}(e, X) = Pr[\BF{s}\cap X \, |\, e, s_u, ec_e]$,
where $X \in \{\CA{F}_i, \CA{B}_i, \CA{F}_i \cup \CA{B}_i\}$.

\subsection{GDTL-FIRM Product MDP}

In this section, we define a construction procedure of
the product MDP between the (belief) TS $\TS$ and
the specification DRA $\RA$.

\begin{definition}[GDTL-FIRM MDP]
\label{def:pa}
Given a DTS $\TS = (\TSX, B_0, \Delta_\TS, \CA{C}_\TS)$,
a Rabin automaton $\RA = (S_\RA, s_0^\RA, \Sigma=\spow{\AP}, \delta, \Omega_\RA)$,
and the transition and intersection probabilities $\pi^{S_\RA}$, $\pi^{\Omega_\RA}$,
their product MDP, denoted by $\PA = \TS \times \RA$, is a tuple
$\PA = (S_\PA, s_0^\PA, Act, \delta_\PA, \Omega_\PA)$ where %:
$s_0^\PA = (B_0 , s_0^\RA)$ is the initial state;
$S_\PA \subseteq \TSX \times S_\RA $ is a finite set of states
which are reachable from the initial state by run of positive probability (see below);
$Act = \TSX$ is the set of actions available at each state;
$\delta_\PA : S_\PA \times Act \times S_\PA \ra [0, 1]$ is the transition probability
defined by $\delta_\PA((B_i, s_i), B_j, (B_j, s_j)) = \pi^{S_\RA}(s_j ; e_{ij}, s_i, \CA{C}_\TS(e_{ij}))$, $e_{ij} = (B_i, B_j)$;
and $\Omega_\PA$ is the set of tuples of good and bad transitions in the product automaton.

%\begin{itemize}
%    \item $s_0^\PA = (B_0 , s_0^\RA)$ is the initial state;
%    \item $S_\PA \subseteq \TSX \times S_\RA $ is a finite set of states
%    which are reachable from the initial state by run of positive probability (see below);
%    \item $Act = \TSX$ is the set of actions available at each state;
%    \item $\delta_\PA : S_\PA \times Act \times S_\PA \ra [0, 1]$ is the transition probability
%    defined by $\delta_\PA((B_i, s_i), B_j, (B_j, s_j)) = \pi^{S_\RA}(s_j ; e_{ij}, s_i, \CA{C}_\TS(e_{ij}))$, $e_{ij} = (B_i, B_j)$;
%    \item $\Omega_\PA$ is the set of tuples of good and bad transitions in the product automaton.
%\end{itemize}
\end{definition}

%    : for every $(x^*, s^*) \in S_\PA$ there exists a sequence of $\BF{x} = x_0 x_1 \ldots x_n x^*$, with $x_k \ra_\TS x_{k+1}$ for all $0 \leq k < n$ and $x_n \ra_\TS x^*$, and a sequence $\BF{s} = s_0 s_1 \ldots s_n s^*$ such that $s_0 = s_0^\RA$, $s_k \ras{h(x_k)}_\RA s_{k+1}$ for all $0 \leq k < n$ and $s_n \ras{h(x_n)}_\RA s^*$;

Denote the set of edges of positive probability by
$\Delta_\PA = \left\{ \big((B_i, s_i), (B_j, s_j) \big) \,|\, \delta_\PA((B_i, s_i), B_j, (B_j, s_j)) > 0 \right\}$.
A transition in $\PA$ is also denoted by
$p_i \ra_\PA p_j$ if $(p_i, p_j) \in \Delta_\PA$.
A trajectory (or run) of {\em positive probability} of $\PA$
is an infinite sequence $\BF{p} = p_0 p_1 \ldots$, where
$p_0 = s^\PA_0$ and $p_k \ra_\PA p_{k+1}$ for all $k \geq 0$.

The acceptance condition for a trajectory of $\PA$ is encoded in
$\Omega_\PA$, and is induced by the acceptance condition of
$\RA$. Formally, $\Omega_\PA$ is a set of pairs
$(\CA{F}^\PA_i, \CA{B}^\PA_i)$, where
$\CA{F}^\PA_i = \{ e \in \Delta_\PA \,|\, \pi^{\Omega_\RA}(e, \CA{F}_i) > 0\}$,
$\CA{B}^\PA_i = \{ e \in \Delta_\PA \,|\, \pi^{\Omega_\RA}(e, \CA{B}_i) > 0\}$,
and $(\CA{F}_i, \CA{B}_i) \in \Omega_\RA$.

A trajectory of $\PA = \TS \times \RA$ is said to be accepting
if and only if there is a tuple $(\CA{F}^\PA_i, \CA{B}^\PA_i) \in \Omega_\PA$
such that the trajectory intersects the sets $\CA{F}^\PA_i$ and $\CA{B}^\PA_i$
infinitely and finitely many times, respectively.
It follows by construction that a trajectory $\BF{p} = (B_0, s_0) (B_1, s_1) \ldots$ of $\PA$
is accepting if and only if the trajectory $\BF{s}^0_{0:T_0-1} \BF{s}^1_{0:T_1-1} \ldots$
is accepting in $\RA$,
where $\BF{s}^i_{0:T_i}$ is the random trajectory of $\RA$ obtained
by traversing the transition $e = (B_i, B_{i+1})$ using the controller
$\CA{C}_\TS(e)$ and $s^i_{0} = s_i$ for all $i \geq 0$. Note that $\BF{s}^i_{T_i} = \BF{s}^{i+1}_0$.
As a result, a trajectory of $\TS$ obtained from an accepting trajectory of $\PA$
satisfies the given specification encoded by $\RA$ with positive probability.
%
%For $x \in X$, we define $\beta_\PA(x) = s \in S_\RA$ such that  $(x, s) \in S_\PA$ as the Rabin automaton state that corresponds to $x$ in $\PA$.
We denote the projection of a trajectory
$\BF{p} = (B_0, s_0) (B_1, s_1) \ldots$ onto $\TS$ by
$\proj{\BF{p}}{\TS} = B_0 B_1 \ldots$.
A similar notation is used for projections of finite trajectories.

\begin{remark}
Note that the product MDP in Def.~\ref{def:pa} is defined to be amenable to
incremental operations with respect to the growth of the DTS, i.e., updating and
checking for a solution of positive probability.
This property is achieved by requiring the states of $\PA$ to be reachable
by transitions in $\Delta_\PA$.
The incremental update can be performed using a recursive procedure
similar to the one described in~\cite{VaBe-IROS-2013}.
\end{remark}
\begin{remark}
The acceptance condition for $\PA$ is defined by its transitions and not in the usual way in terms
of its states, % the usual way.
%The choice is
due to the stochastic nature of transitions between belief
nodes in $\TS$. We only record the initial and end DRA states of the
DRA trajectories induced by the sample paths obtained using the local
controllers.
%Our construction is conservative, but avoids the need to store a (possibly large)
%number of intermediate states in $\PA$ for spurious sample paths % which deviate
%deviating
%from the nominal one.
%Thus, the burden of the search is shifted from the verification component
%of the solution, to the sampling-based search procedure.
%A heuristic argument for our choice is that most of the time sample paths
%swill generate the same DRA trajectory as the nominal path.
\end{remark}


%For brevity, we omit its description and refer the reader to~\cite{VaBe-IROS-2013}.

\subsection{Finding satisfying policies}%Checking existence for satisfying paths}

The existence of a satisfying policy with positive probability can be checked efficiently
on the product MDP $\PA$ by maintaining end components EC\footnote{An
EC of an MDP is a sub-MDP  such that there exists a policy such that each
node in the EC can be reached from each other node in the EC with positive
probability.}
for induced subgraphs of $\PA$ determined by the pairs in the acceptance
condition $\Omega_\PA$.
%An SCC is a subgraph such that each node in the SCC can be reached from each other node in the SCC.
For each pair $\CA{F}^\PA_i, \CA{B}^\PA_i$, let $c_i$ denote the
ECs associated with the graphs $G^\PA_i = (S_\PA,\Delta_\PA \setminus \Gamma_i)$, where
$\Gamma_i =  \{ (p, p') \in \Delta_\PA \,|\, \pi^{\Omega_\RA}(e, \CA{F}_i) = 0 \wedge \pi^{\Omega_\RA}(e, \CA{B}_i) > 0, e=\proj{(p, p')}{\TS} \}$.
%Let $dag_i$ be the directed acyclic graphs (DAGs) associated with $scc_i$.
Given $c_i$, checking for a satisfying trajectory in procedure $existsSatPolicy(\PA)$
becomes trivial.
We test if there exists an EC %reachable in $dag_i$ from the SCC containing $s^\PA_0$
that contains a transition $(p, p')$ such that
$\pi^{\Omega_\RA}(e, \CA{F}_i) > 0$, where $e=\proj{(p, p')}{\TS}$.
Note that we do not need to maintain $\Omega_\PA$ explicitly, we only
need to maintain the  $c_i$.
Efficient incremental algorithms to maintain these ECs were proposed
in~\cite{Haeupler2012}. %,Bender2015

\subsection{Dynamic program for Maximum Probability Policy}
\input{DP}

%\subsection{Querying the FIRM}

\subsection{Complexity}
The overall complexity of maintaining the ECs used for checking
for satisfying runs in $\PA$ is $O(\card{\Omega_\RA} \card{S_\PA}^{\frac{3}{2}})$.
The complexity bound is obtained using the algorithm described
in~\cite{Haeupler2012} and is better by a polynomial factor
$\card{S_\PA}^{\frac{1}{2}}$ than computing the ECs at each
step using a linear algorithm.
Thus, checking for the existence of a satisfying run of positive probability
can be done in $O(\card{\Omega_\RA})$ time.
The dynamic programming algorithm is polynomial in
$\card{S_\PA}$~\cite{papadimitriou1987}.

%{\color{blue} [To be written by Cristi]
%
%For all TS, DRA and MDP, we use $\card{\cdot}$ to denote size,
%which is the cardinality of the corresponding set of states.
%
%\begin{itemize}
%  \item the overall complexity of maintaining the SCCs is $O(\card{\Omega_\RA} n^{\frac{3}{2}})$, where $\card{\TS} \leq n = \card{\PA} \leq \card{\TS} \cdot \card{\RA}$, if:
%  \begin{itemize}
%    \item $\TS$ is a sparse graph; and
%    \item the incremental SCC algorithm used to update the SCCs has overall complexity $O(n^{\frac{3}{2}})$.
%  \end{itemize}
%  \item the first part of the test can be checked in $O(1)$ if one maintains $F_\PA$, which resembles the case of a product with a \buchi
%  \item the complexity of checking for the existence of satisfying path is $O(\card{\Omega_\RA})$
%\end{itemize}
%
%}

%\subsection{Conclusion of Running Example}

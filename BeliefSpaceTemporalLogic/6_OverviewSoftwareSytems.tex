\documentclass[conference]{IEEEtran}
\usepackage{standalone}
\usepackage{times}
\usepackage{float}

\input{TemplateFiles/def.tex}
\input{TemplateFiles/inc}

% numbers option provides compact numerical references in the text. 

\pdfinfo{
   /Author (Homer Simpson)
   /Title  (Robots: Our new overlords)
   /CreationDate (D:20101201120000)
   /Subject (Robots)
   /Keywords (Robots;Overlords)
}

% Table caption wrangling
\usepackage{etoolbox}
\makeatletter
\patchcmd{\@makecaption}
  {\scshape}
  {}
  {}
  {}
\makeatletter
\patchcmd{\@makecaption}
  {\\}
  {.\ }
  {}
  {}
\makeatother

\newcommand{\Ali}[1]{{\color{green} Ali: #1}}
\newcommand{\cristi}[1]{{\color{orange} Cristi: #1}}
%\newcommand{\rohan}[1]{{\color{blue} Rohan: #1}}
\newcommand{\kyon}[1]{{\color{cyan} #1}}
\newcommand{\done}[1]{{\color{gray} #1}}
\allowdisplaybreaks[1]

\begin{document}

% paper title
%\title{\large From Mission Specification to Safe Control Logic Under Uncertainty:\\ Application to Mars Copter-Rover Navigation-Coordination}

\title{\huge Software/Systems}

\author{Kyon, Rohan, Petter, Kamak, Cristi, Sofie, Ali Agha, Richard Murray, Aaron Ames}

\maketitle

\begin{abstract}
This report summarizes the software architecture and the system description for V\&V tasks. 
\end{abstract}

\IEEEpeerreviewmaketitle

	
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction} \label{subsec:intro}

To verify the validity of the algorithms, we have built an end-to-end system based on ROS (Robot Operating System). Each module in the system communicates each other using the predefined message types over ROS's synchronous/asynchronous communication infrastructure. The modular architecture provides an abstraction of hardware, which enables testing with both hardware and simulation using the same code base. 

\section{Software Architecture}

A high-level software architecture is shown in Fig.~\ref{fig:software_arch}. Each node in the graph roughly corresponding to a single ROS node (process). The background color represents the status of node development. 

\textit{Belief space planner} is a core planning node running on the ground vehicle. It takes a map from the copter (and possibly from rover's navigation cameras) as input, and generates a policy for the rover's motion and next measurement plans for the copter. 

\textit{Policy executor} receives the policy from the planner, and translates the policy to the form that the locomotion node can understand (e.g., next waypoint coordinates).

\textit{Locomotor} accepts two types of commands: arc and waypoint. The arc command directly specifies three arc parameters, namely length, angle change, and direction . The waypoint command specifies $x$ and $y$, with the option of additional heading $\theta$. 

\textit{Pose estimator} is an EKF fusing the information from motor commands, an IMU, and cameras. The estimator gives a mean pose estimate with covariance.


The other modules are mock at this moment. The descriptions will be updated as they proceed. 




\subsection{Simulation}

We use the Gazebo simulation framework\footnote{http://gazebosim.org}, which comes with physics and graphics computation engines with potential ROS integration. We chose Gazebo over the JPL in-house simulation framework (DARTS) for the ease of multi-institutional collaboration. 

Our focus in the simulation is sorely on the validation of the planning pipeline, rather than high-fidelity physics-based evaluation. Therefore, simplified models will be used wherever reasonable.

\subsection{Environmental Models}

\begin{figure}
    \centering
    %\includegraphics[width=\textwidth]{BeliefSpaceTemporalLogic/figs/GazeboScene}
    \caption{Mars terrain loaded in the Gazebo simulator}
    \label{fig:gazebo_scene}
\end{figure}

We use Martian terrain models from the JPL OnSight project. Their map processing pipeline produces photo-realistic terrain geometry from MSL Curiosity's surface imagery. An example scene is shown in Fig.~\ref{fig:gazebo_scene}.

\subsection{Robot Models}
TBD


\section{Hardware Testbed}

\subsection{Ground rover (Athena/JPL)}


\subsection{Aerial copter (Caltech)}



\section{Scenario}
\begin{itemize}
  \item Map Building
  \item Map Labelling
\end{itemize}

\begin{figure}[th!]
	\centering
	\includegraphics[width=\columnwidth]{figs/FunctionalArcV4.png}
	\caption{Architecture showing mapping, planning and execution framework.}
	\label{fig:FuncArc}
\end{figure}    	

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}
    \centering
    \includegraphics[width=\textwidth]{BeliefSpaceTemporalLogic/figs/SoftwareArch.jpg}
    \caption{Software architecture}
    \label{fig:software_arch}
\end{figure*}



\clearpage
\section{Development Status}

Below is the development status as of January 3.

\subsection{Core Navigation Modules}

\subsubsection{Perception}

\paragraph{Stereo Reconstruction (complete)}
\done{
The JPLV stereo vision has been implemented. It provides point cloud up to 7-8m. 
}

\paragraph{Terrain Classification (development complete; copter test requires 1 week; multi-class extention requires 1+ month)}
The SPOC-lite classifier provides the probability (confidence) of sand given a single color image. The SPOC-lite is essentially a 5-class classifier based on SVM Linear \cite{liblinear}. It is specialized to detect the white sand regions in the JPL Mars yard (the accuracy is $>$98\%).

As it is trained for rover's downward-looking mast camera, the performance is unknown for copter's imagery. The Mars yard test requires about a week. 

Extra labeling and training may be required for the following cases: reliable multi-class classification, classification in different environment (e.g., JPL mini Mars yard, Caltech wind tunnel). 


\paragraph{Traversability Assessent (complete; adaption requires up to 2-3 days)}
\done{
The Morphin traversability analyzer (the ancestor of MER/MSL GESTALT) is implemented. The adaptation to different terrain requires intensive parameter tuning. For stable performance, 2-3 day testing will be required.
}


\subsubsection{State Estimation}

\paragraph{Visual Odometry (complete)}
\done{
The JPL VO provides 6DoF pose information in 3.75 Hz. 
}

\paragraph{IMU (completed)}
\done{
An IMU is mounted on Athena, and publishing data as sensor\_msgs/IMU messages.
}

\paragraph{EKF (2-3 months?; 2-3 weeks for 3rdparty option)}
There is an effort to implement an EKF that fuses wheel odometry, visual odometry, and IMU. It is under testing on a benchtop model. No ROS wrapper presents.

On special need,  the 3rdparty EKF like robot\_localization\footnote{\url{http://wiki.ros.org/robot_localization}} may be installed. This will use VO and WO as odometry input. The integration and testing requires about 2-3 weeks.


\subsubsection{Actuation}

\paragraph{Locomotion (complete; 2 weeks to implement visual feedback; 3 months for proper velocity distribution over articulated suspention)}
\done{
The locomotion module drives a rover to a designated point. The destination is specified either by $ (x, y, \theta) $ or arc parameters. Each wheel is separately controlled in terms of position and velocity.

The vision-based path tracking is not implemented. It requires about two weeks to implement and test. 
\kyon{The visual feedback will not be implemented at this level, as the higher level planner can handler the execution uncertainty.}

The suspension model is not incorpolated into the velocity distribution to six wheels. Therefore, actuation error may be innegligible in undulating terrain. This requires suspention angle measurements which are not possible with the current hardware configurations. 
\kyon{This is not critical as well. The suspension measurements will not be implemented in the near future.}
}


\paragraph{Mast Actuation (complete)}
\done{
The mast actuation module moves the mast gymbal to a designated direction. The direction is specified using the cartesian coordinates (XYZ) or joint angles (azimuth and elevation). 
}



\subsection{Gazebo Simulation}

\paragraph{Environmental Model (visual complete; physical 1 week)}
Realistic Martian terrain models are already available in Gazebo. If physical interaction is needed, surface parameters should be tuned to produce natural rover motions. 

\paragraph{Rover Model (1 week for visual; 2 weeks for physical)}
The rocker-bogie rover model is not available in DARTS. The visualization takes about a week to move the vehicle parts (suspention, wheels).
\kyon{A visual model for rocker-bogie rover (Curiosity) is partially completed. See Fig.~ \ref{fig:msl_visual}. The mast joints are not yet implemented.}

The physical model is completely unavailable. Porting from DARTS models should take about 2 weeks.

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figs/report6/msl_visual.png}
    \caption{Visual model for the Curiosity rover.}
    \label{fig:msl_visual}
\end{figure}



\paragraph{Copter Model (quadcopter visual available; helicopter visual 1 week; 3 day to emulate heli camera; 1-2 months for full aerodynamics simulation)}
The estimate work time for the mock helicopter is one week. If it requires full simulation (I hope not), it will take months. 

\kyon{Implemented simple visual model as shown in Fig.~\ref{fig:copter_visual}. Not sure if the Mars helicopter model is publicly available.}

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{figs/report6/copter_visual.png}
    \caption{Visual model for the Curiosity rover.}
    \label{fig:msl_visual}
\end{figure}




\done{
\subsection{DARTS Simulation}

\kyon{We will not implement models in DARTS framework.}

Generally, using DARTS requires a steep learning curve. For those who don't have experience with DARTS, it takes 1-2 more months in learning before working on practical tasks. 

\paragraph{Environmental Model (visual 1 week; physical 1 week)}
The same Martian model may be installed onto the DARTS environment as well. It takes up to two weeks to fully integrated in the system.

\paragraph{Rover Model (complete)}
Various rocker-bogie rover models are available as a part of ROAMS.

\paragraph{Copter Model (1-2 weeks?)}
A few copter models are available as a part of DSENDS. It may take 1-2 weeks to learn to control copters.

\paragraph{ROS interface (3 weeks)}
Significant effort needed to connect DARTS simulator with the ROS interface. There is a prototype implementation for ROAMS. It will take about 3 weeks to expose all relevant functionalities to ROS.
}

\subsection{Decision}
As of December 12, we decided to go with the simulation only (possibly with Gazebo). The estimate work time is about 10 weeks (around the end of February). 

This is not the final decision. As the project proceeds, we may make a replan based on the belief we have at the point. We will review the progress at roughly each end of months. 


\begin{thebibliography}{99}
\bibitem{liblinear}
LIBLINEAR, \url{https://www.csie.ntu.edu.tw/~cjlin/liblinear/}.

\end{thebibliography}

\end{document}

